{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Conv2D(128, (5, 5), subsample=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    total = generated_images.shape[0]\n",
    "    cols = int(math.sqrt(total))\n",
    "    rows = math.ceil(float(total)/cols)\n",
    "    width, height = generated_images.shape[1:3]\n",
    "    combined_image = np.zeros((height*rows, width*cols),\n",
    "                              dtype=generated_images.dtype)\n",
    "\n",
    "    for index, image in enumerate(generated_images):\n",
    "        i = int(index/cols)\n",
    "        j = index % cols\n",
    "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[0, :, :]\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 20\n",
    "GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n",
    "\n",
    "def train():\n",
    "    (X_train, y_train), (_, _) = mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "    # generator+discriminator （discriminator部分の重みは固定）\n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "\n",
    "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Number of batches:', num_batches)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "\n",
    "            # 生成画像を出力\n",
    "            if index % 500 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5 + 127.5\n",
    "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "                Image.fromarray(image.astype(np.uint8))\\\n",
    "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
    "\n",
    "            # discriminatorを更新\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # generatorを更新\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
    "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
    "\n",
    "        generator.save_weights('generator.h5')\n",
    "        discriminator.save_weights('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), strides=(2, 2))`\n",
      "  \n",
      "/Users/mikio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1875\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-f39ab3db14b7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# discriminatorを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 28, 28, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = generator_model()\n",
    "BATCH_SIZE = 32\n",
    "noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "generated_images = generator.predict(noise, verbose=0)\n",
    "\n",
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb30df4ef0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(generated_images[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = generated_images.shape[0]\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = int(math.sqrt(total))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = math.ceil(float(total)/cols)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width, height = generated_images.shape[1:3]\n",
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image = np.zeros((height*rows, width*cols),\n",
    "                              dtype=generated_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image.shape\n",
    "for index, image in enumerate(generated_images):\n",
    "        i = int(index/cols)\n",
    "        j = index % cols\n",
    "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 140)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = X_train[index*32:(index+1)*32]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
